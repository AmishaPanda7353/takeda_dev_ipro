{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/ta_ipro/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ec2-user/anaconda3/envs/ta_ipro/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from src.main import InsightsPro\n",
    "import glob\n",
    "from core.utils.client_utils import  get_vectordb_client\n",
    "import json\n",
    "from src.query_insights.entity_extraction import EntityExtraction\n",
    "from core.utils.client_utils import get_model_type,get_entity_extraction_client\n",
    "from core.model.model_factory import ModelFactory\n",
    "from core.utils.read_config import config,initialize_config\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain name\n",
    "domain_name = \"mcd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_config, data_config, model_config, debug_config = initialize_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was the sales of my stores in the last 1 year?\"\n",
    "additional_context = None\n",
    "language = \"english\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Entity Extraction Data Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/data_dictionary/playbook_table.json\n",
      "../../data/data_dictionary/gc_table.json\n",
      "../../data/data_dictionary/recommendation_table.json\n",
      "../../data/data_dictionary/summary_category_channel_table.json\n",
      "../../data/data_dictionary/snapshot_table.json\n",
      "../../data/data_dictionary/summary_item_channel_price_table.json\n",
      "../../data/data_dictionary/summary_store_table.json\n",
      "../../data/data_dictionary/summary_item_channel_view.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../../data/entity_extraction_data_dictionary/\",exist_ok=True)\n",
    "for name in glob.glob( \"../../data/data_dictionary/\"+ \"*.json\"):\n",
    "        print(name)\n",
    "        with open(name,\"r\") as file:\n",
    "            json_file = json.load(file)\n",
    "        filename=name.replace('data_dictionary','entity_extraction_data_dictionary')\n",
    "        with open(filename,\"w\") as file:\n",
    "            json.dump(json_file,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InsightsPro Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "insightspro = InsightsPro(user_config=user_config,\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    debug_config=debug_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_overview = insightspro.generic_initializations.business_overview\n",
    "prompts = model_config.extract_formulas.prompts\n",
    "model_params = model_config.extract_formulas.model_params\n",
    "data_dictionary = insightspro.dataloader.data_dictionary\n",
    "data_dictionary_path = data_config.path.data_dictionary_path\n",
    "entity_extraction_data_dictionary_path = data_config.path.entity_extraction_data_dictionary_path\n",
    "categorical_dict_path = \"../../data/output_folder/categorical_values.json\"\n",
    "\n",
    "#Initializing EntityExtraction class\n",
    "entityextraction = EntityExtraction()\n",
    "entity_extraction_model = get_entity_extraction_client(config.entity_extraction_details,data_dictionary)\n",
    "with open(categorical_dict_path,\"r\") as file:\n",
    "    categorical_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of formulas from document using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"llm_model_type\"] = \"openai\"\n",
    "model_client = get_model_type(config,prompts,None,None,user_config.connection_params,user_config,None,None,business_overview,None,None,)\n",
    "model_factory = ModelFactory(model_client)\n",
    "formula_data_dictionary, model_finish,model_tokens,error_message, = model_factory.model_type.model_response(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing output string to JSON format\n",
    "formula_data_dictionary = eval(formula_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_units': ['current_units',\n",
       "  'price_elasticity',\n",
       "  'new_price',\n",
       "  'current_price'],\n",
       " 'Sales': ['Units', 'Price'],\n",
       " 'new_sales': ['new_price', 'new_units'],\n",
       " 'current_sales': ['current_price', 'current_units'],\n",
       " 'Change in sales': ['new_sales', 'current_sales'],\n",
       " 'Margin': ['Price', 'Cost', 'Units'],\n",
       " 'new_margin': ['new_price', 'current_fpc', 'new_units'],\n",
       " 'current_margin': ['current_price', 'current_fpc', 'current_units'],\n",
       " 'Increase in margin': ['new_margin', 'current_margin'],\n",
       " 'Margin impact': ['new_margin', 'current_margin'],\n",
       " 'WAP at current_price': ['current_price', 'current_units'],\n",
       " 'WAP at new_price': ['new_price', 'current_units'],\n",
       " 'WAP impact': ['new_price',\n",
       "  'current_units',\n",
       "  'sum_current_units',\n",
       "  'current_price'],\n",
       " 'Impact on wap': ['new_price',\n",
       "  'current_units',\n",
       "  'sum_current_units',\n",
       "  'current_price'],\n",
       " 'new_gc': ['current_gc_per_week', 'gc_elasticity', 'new_wap', 'current_wap'],\n",
       " 'GC impact': ['gc.current_gc',\n",
       "  'gc.gc_elasticity',\n",
       "  'wp.new_wap',\n",
       "  'wp.current_wap'],\n",
       " 'impact on GC': ['gc.current_gc',\n",
       "  'gc.gc_elasticity',\n",
       "  'wp.new_wap',\n",
       "  'wp.current_wap'],\n",
       " 'Delivery premium for an item': ['delivery_price', 'instore_price'],\n",
       " 'new_delivery_premium for an item': ['new_price', 'instore_item_new_price'],\n",
       " 'current_delivery_premium for an item': ['current_price',\n",
       "  'instore_item_current_price'],\n",
       " 'flowthrough': ['new_revenue_per_week',\n",
       "  'current_revenue_per_week',\n",
       "  'new_wap',\n",
       "  'current_wap']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Data Dictionary to run Entity Extraction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run Entity extraction model following data have to be added to data dictionary :\n",
    "1)create entity_datecolumn key if the description contains date pattern.<br>\n",
    "2)create metrics key with metrics if the column is used to calculate any metrics.<br>\n",
    "3)Add metrics information to description if the column is used for metrics calculation.<br>\n",
    "4)Processes column name that includes lowercase, replaces hyphens and underscores, lemmatization and replace id string with space if the text ends with id.<br>\n",
    "5)create entity_description key to store a list of entities for description using entity extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/entity_extraction_data_dictionary/playbook_table.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/entity_extraction_data_dictionary/gc_table.json\n",
      "../../data/entity_extraction_data_dictionary/recommendation_table.json\n",
      "../../data/entity_extraction_data_dictionary/summary_category_channel_table.json\n",
      "../../data/entity_extraction_data_dictionary/snapshot_table.json\n",
      "../../data/entity_extraction_data_dictionary/summary_item_channel_price_table.json\n",
      "../../data/entity_extraction_data_dictionary/summary_store_table.json\n",
      "../../data/entity_extraction_data_dictionary/summary_item_channel_view.json\n"
     ]
    }
   ],
   "source": [
    "def add_entities_to_data_dictionaries(entity_extraction_data_dictionary_path, formula_data_dictionary,entityextraction,entity_extraction_model,categorical_dict):\n",
    "\n",
    "    for name in glob.glob(entity_extraction_data_dictionary_path + \"*.json\"):\n",
    "        print(name)\n",
    "        with open(name,\"r\") as file:\n",
    "            json_file = json.load(file)\n",
    "\n",
    "        for dict2 in json_file['columns']:\n",
    "            #create entity_datecolumn key if the description contains date pattern\n",
    "\n",
    "            if entityextraction._contain_datetime(dict2['description'].lower()):\n",
    "                dict2['entity_datecolumn'] =  'Yes'\n",
    "            else:\n",
    "                dict2['entity_datecolumn'] = 'No'\n",
    "\n",
    "            #create metrics key with metrics if the column is used to calculate any metrics\n",
    "            if \"metrics\" not in dict2.keys():\n",
    "                dict2['metrics'] = []\n",
    "\n",
    "            #Add metrics information to description if the column is used for metrics calculation\n",
    "            for lhs,rhs in formula_data_dictionary.items():\n",
    "                lhs = lhs.lower()\n",
    "                lhs_flag = False\n",
    "                rhs = [r.lower() for r in rhs]\n",
    "                for match in rhs:\n",
    "                    if \".\" in match:\n",
    "                        match = match.split(\".\")[1]\n",
    "                    match = match.strip()\n",
    "                    if dict2['name']==match:\n",
    "                        if not lhs_flag:\n",
    "                            dict2['description'] = (dict2['description']+\". '\"+lhs+\"' is calculated using this column.\")\n",
    "                            lhs_flag = True\n",
    "                        dict2['metrics'].append(lhs)\n",
    "\n",
    "            dict2['description'] = dict2['description'].replace(\"..\",\".\").replace(\".. \",\". \")\n",
    "            dict2['metrics'] = list(set(dict2['metrics']))\n",
    "\n",
    "            #Processes column name that includes lowercase, replaces hyphens and underscores, lemmatization and replace id string with space if the text ends with id\n",
    "            column_name = ''\n",
    "            if dict2['name'].endswith(\"_id\"):\n",
    "                column_name = dict2['name'].replace(\"_id\", \"\")\n",
    "            elif dict2['name'].endswith(\"_name\"):\n",
    "                column_name = dict2['name'].replace(\"_name\", \"\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if column_name!='':\n",
    "                dict2['entity_name'] = [entityextraction._lemmatization(column_name)]\n",
    "            else:\n",
    "                dict2['entity_name'] = [entityextraction._lemmatization(dict2['name'])]\n",
    "\n",
    "            #create entity_description key to store a list of entities for description using entity extraction model.\n",
    "\n",
    "            entity_extraction_model = get_entity_extraction_client(config.entity_extraction_details,data_dictionary)\n",
    "            entity_extraction_model.get_entities(entityextraction._lemmatization(dict2['description']))\n",
    "\n",
    "            model_entities = entity_extraction_model.entities\n",
    "\n",
    "            entities = []\n",
    "            for tup in model_entities:\n",
    "\n",
    "                entities.append(tup[0])\n",
    "            dict2['entity_description'] =  list(set(entities))\n",
    "\n",
    "            if \"entity_categorical_values\" not in dict2.keys():\n",
    "                dict2['entity_categorical_values'] = []\n",
    "\n",
    "\n",
    "            for key,cat_values in categorical_dict.items():\n",
    "                tab_name, col_name = (\n",
    "                        key.split(\",\")[0],\n",
    "                        key.split(\",\")[1],\n",
    "                    )\n",
    "                if tab_name==json_file['table_name'] and col_name==dict2['name']:\n",
    "                    cat_list = []\n",
    "                    for cat_value in cat_values:\n",
    "                        if cat_value:\n",
    "                            cat_list.append(cat_value.replace(\"-\", \" \").replace(\"_\", \" \").lower())\n",
    "                    dict2['entity_categorical_values'].extend(cat_list)\n",
    "        # entity_extraction_data_dictionary_path = data_dictionary_path.replace('data_dictionary','entity_extraction_data_dictionary')\n",
    "        # os.makedirs(entity_extraction_data_dictionary_path,exist_ok=True)\n",
    "        # filename = name.replace('data_dictionary','entity_extraction_data_dictionary')\n",
    "        with open(name,\"w\") as file:\n",
    "            json.dump(json_file,file)\n",
    "\n",
    "add_entities_to_data_dictionaries(entity_extraction_data_dictionary_path,formula_data_dictionary,entityextraction,entity_extraction_model,categorical_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Till This Cell To Use Table Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of logic and examples from document using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/mcd/complex_questions_glossary.txt\") as file:\n",
    "    complex_questions_glossary = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"llm_model_type\"] = \"openai\"\n",
    "prompts = model_config.complex_questions_extract_logic.prompts\n",
    "model_params = model_config.complex_questions_extract_logic.model_params\n",
    "\n",
    "model_client = get_model_type(config,prompts,None,None,user_config.connection_params,user_config,None,None,complex_questions_glossary,None,None,)\n",
    "model_factory = ModelFactory(model_client)\n",
    "logic_complex_questions, model_finish,model_tokens,error_message, = model_factory.model_type.model_response(model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_complex_questions = eval(logic_complex_questions[13:-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logic 1: The number of items recommended in a store depends on the number of items with low sensitivity or self-elasticity. Items falling under low sensitivity/self -elasticity bin are likely to receive price change compared to items falling under medium and high sensitivity bins. The reasons behind a price recommendation or lack of it is present in the reason code column. columns required - playbook_table.selfelasticity_bin,playbook_table.reason_code': ['Why does big mac not have a recommendation in my store in delivery channel?',\n",
       "  'Only 5 cents increase is recommended in item 5 in instore channel. Why is that?',\n",
       "  'Why does a low sensitive item not get recommendation in my store in delivery channel?',\n",
       "  'Item 5 has a negative impact in instore channel. Why did it get recommendation?'],\n",
       " 'Logic 2: To calculate margin impact of a metric if we increase the price of an item by x cents, pls follow the below steps. 1. Increase the new_price for item_y by x cents to get new_price_after_price_increase. 2. Calculate new_margin = ((new_price - current_fpc) * new_units 2. Calculate new_units_after_price_increase = (current_units * exp(price_elasticity * ln((new_price_after_price_increase)/current_price))) 3. Calculate new_margin_after_price_increase = new_price_after_price_increase - cost) * new_units_after_price_increase 4. Margin Impact after additional price increase = new_margin_after_price_increase - new_margin columns required - recommendation_table.new_price,recommendation_table.current_units,recommendation_table.price_elasticity,recommendation_table.current_price,recommendation_table.new_units': ['What is the margin impact for store 84000006 after increasing the price for item 5 by 10 cents in instore channel?',\n",
       "  'Calculate the margin impact for my store if we increase the price for big mac by 10 cents in delivery channel.',\n",
       "  'What is the margin impact for store 84000006 after increasing the price for item 5 by 10 cents?'],\n",
       " 'Logic 3: To calculate WAP impact of a metric if we increase the price of an item by x cents, pls follow the below steps. 1. Get new_wap from summary_store_table for the store 2. Increase the new_price for item_y by x cents. 3. Calculate new_wap_after_price_increase = sum(new_price * current_units)/sum(current_units) 4. WAP Impact after additional price increase = new_wap_after_price_increase - new_wap columns required - summary_store_table.new_wap,recommendation_table.new_price,recommendation_table.current_units': ['What is the WAP impact for store 84000006 after increasing the price for item 5 by 10 cents in instore channel?',\n",
       "  'Calculate the WAP impact for my store if we increase the price for big mac by 10 cents in delivery channel.',\n",
       "  'What is the WAP impact for store 84000006 after increasing the price for item 5 by 10 cents?'],\n",
       " 'Logic 4: To calculate GC impact of a metric if we increase the price of an item by x cents, pls follow the below steps. 1. Get current_wap from summary_store_table for the store 2. Increase the new_price for item_y by x cents. 3. Calculate new_wap_after_price_increase = sum(new_price * current_units)/sum(current_units) 4. Calculate new_gc_after_price_increase = (current_gc * EXP(gc_elasticity * LN(new_wap_after_price_increase / current_wap)) 5. GC Impact after additional price increase = new_gc_after_price_increase - new_gc columns required - recommendation_table.new_price,recommendation_table.current_units,gc_table.current_gc,gc_table.new_gc,summary_store_table.current_wap,gc_table.gc_elasticity': ['What is the GC impact for store 84000006 after increasing the price for item 5 by 10 cents in instore channel?',\n",
       "  'Calculate the GC impact for my store if we increase the price for big mac by 10 cents in delivery channel.',\n",
       "  'What is the GC impact for store 84000006 after increasing the price for item 5 by 10 cents?']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logic_complex_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating similar questions for the questions in logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"llm_model_type\"] = \"openai\"\n",
    "prompts = model_config.generate_similar_questions.prompts\n",
    "model_params = model_config.generate_similar_questions.model_params\n",
    "i = 0\n",
    "question_df = pd.DataFrame(columns= ['chunk_type','chunk','tables_columns'])\n",
    "for logic, questions_list in logic_complex_questions.items():\n",
    "    for ques in questions_list:\n",
    "        model_client = get_model_type(config,prompts,ques,None,user_config.connection_params,user_config,None,None,None,None,None,)\n",
    "        model_factory = ModelFactory(model_client)\n",
    "\n",
    "        output_, model_finish,model_tokens,error_message, = model_factory.model_type.model_response(model_params)\n",
    "        output_ = output_[9:-7].split(\",\\n\")\n",
    "        output_= [x.replace(\"\\\"\",\"\") for x in output_ if x!='' and len(x)>15]\n",
    "        table_column = logic.split('columns required - ')[1]\n",
    "        question_df.loc[i]  = logic,re.sub(r'\\d+', '', ques),table_column.strip()\n",
    "        for q in output_:\n",
    "           i = i+1\n",
    "           question_df.loc[i] = logic,re.sub(r'\\d+', '', q),table_column.strip()\n",
    "        i=i+1\n",
    "for text in business_overview.split(\"\\n\"):\n",
    "    if text!=\"\":\n",
    "        question_df.loc[i] = \"Glossary : \"+text,text,\"\"\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Embeddings for questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus at localhost:19530\n",
      "Creating Collection: my_collection_chunk\n",
      "Creating Index for chunk\n",
      "Inserting data into chunk\n"
     ]
    }
   ],
   "source": [
    "question_df['unique_id'] = question_df.index+1\n",
    "question_df = question_df[['unique_id','chunk_type','chunk','tables_columns']]\n",
    "vector_db = get_vectordb_client(config.embedding_details, question_df)\n",
    "vector_db.insert_data()\n",
    "chunk_embeddings = vector_db.data_frame\n",
    "chunk_embeddings['embeddings']=chunk_embeddings['embeddings'].apply(lambda x: x.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings.to_excel(\"../data/mcd/chunk_embeddings.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils.client_utils import get_entity_extraction_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extraction = get_entity_extraction_client(\n",
    "                config.entity_extraction_details, insightspro.dataloader.data_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question =\"What is the distribution of price change by Category for store 84000006?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extraction.get_entities(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('price', 0.417),\n",
       " ('84000006', 0.372),\n",
       " ('store', 0.3677),\n",
       " ('distribution', 0.3673),\n",
       " ('category', 0.3376),\n",
       " ('price change', 0.6122),\n",
       " ('distribution price', 0.5793),\n",
       " ('store 84000006', 0.5361),\n",
       " ('category store', 0.4711),\n",
       " ('price', 0.417)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_extraction.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('84000006', 0.372) ['84000006']\n",
      "('store', 0.3677) ['instore']\n",
      "('84000006', 0.372) ['84000006']\n",
      "('store', 0.3677) ['instore']\n",
      "('84000006', 0.372) ['84000006']\n",
      "('store', 0.3677) ['instore']\n",
      "('price', 0.417) ['no price change : adjustment beyond optimizer to preserve price architecture rule', 'price change : adjustment beyond optimizer to fix a business rule', 'partial increase: recommended increase to maintain price architecture rules', 'no increase: price architecture rules restrict any recommended increase', 'full increase: recommended increase to maintain price architecture rules', 'no increase: held to avoid high price changes for aligning price architecture', 'partial increase: positive margin and revenue impact limited by price architecture rules']\n",
      "('store', 0.3677) ['no increase: triggers store performance safeguards, not enough positive revenue and margin impact to justify risk', 'partial increase: further increase limited by store performance safeguards']\n",
      "('price change', 0.6122) ['no price change : adjustment beyond optimizer to preserve price architecture rule', 'price change : adjustment beyond optimizer to fix a business rule', 'no increase: held to avoid high price changes for aligning price architecture']\n",
      "('price', 0.417) ['no price change : adjustment beyond optimizer to preserve price architecture rule', 'price change : adjustment beyond optimizer to fix a business rule', 'partial increase: recommended increase to maintain price architecture rules', 'no increase: price architecture rules restrict any recommended increase', 'full increase: recommended increase to maintain price architecture rules', 'no increase: held to avoid high price changes for aligning price architecture', 'partial increase: positive margin and revenue impact limited by price architecture rules']\n",
      "('store', 0.3677) ['instore']\n",
      "('84000006', 0.372) ['84000006']\n",
      "('store', 0.3677) ['instore']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for table_name, table_data in insightspro.dataloader.data_dictionary.items():\n",
    "    for dictionary in table_data[\"columns\"]:\n",
    "        for entity in entity_extraction.entities:\n",
    "            pattern = re.compile(entity[0], re.IGNORECASE)\n",
    "            matching_items = [item for item in dictionary['entity_categorical_values'] if pattern.search(item)]\n",
    "            if matching_items:\n",
    "                print(entity,matching_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'entity', re.IGNORECASE|re.UNICODE)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insights_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
